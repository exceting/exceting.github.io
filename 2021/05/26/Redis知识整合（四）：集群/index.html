<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","width":300,"display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="上回主要介绍了redis的主从模式，主从模式最主要的作用是提高redis的可用性，假如主节点挂了，从节点可以在哨兵机制的协助下晋升为主节点继续对外服务，但主从终归是多个redis节点都保存同一份数据，在redis数据快速膨胀时，又该如何应对呢？redis对于这种情况提供了Cluster模式，这是redis的分布式解决方案，使得大批量数据可以拆分成小部分保存进多个redis节点中，本篇笔记将展开说">
<meta property="og:type" content="article">
<meta property="og:title" content="Redis知识整合（四）：集群">
<meta property="og:url" content="http://example.com/2021/05/26/Redis%E7%9F%A5%E8%AF%86%E6%95%B4%E5%90%88%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E9%9B%86%E7%BE%A4/index.html">
<meta property="og:site_name" content="胖虎de文库">
<meta property="og:description" content="上回主要介绍了redis的主从模式，主从模式最主要的作用是提高redis的可用性，假如主节点挂了，从节点可以在哨兵机制的协助下晋升为主节点继续对外服务，但主从终归是多个redis节点都保存同一份数据，在redis数据快速膨胀时，又该如何应对呢？redis对于这种情况提供了Cluster模式，这是redis的分布式解决方案，使得大批量数据可以拆分成小部分保存进多个redis节点中，本篇笔记将展开说">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-1.png?imageView2/0/w/560">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-2.png?imageView2/0/w/600">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-3.png?imageView2/0/w/650">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-5.png?imageView2/0/w/1100">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-7.png?imageView2/0/w/600">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-9.png?imageView2/0/w/600">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-10.png?imageView2/0/w/600">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-11.png?imageView2/0/w/700">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-12.png?imageView2/0/w/600">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-13-fix2.png?imageView2/0/w/1400">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-14.png?imageView2/0/w/850">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-15.png?imageView2/0/w/1100">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-16.png?imageView2/0/w/380">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-17.png?imageView2/0/w/650">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-18.png?imageView2/0/w/500">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-25.png?imageView2/0/w/860">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-27.png?imageView2/0/w/980">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-19.png?imageView2/0/w/560">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-20.png?imageView2/0/w/700">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-22.png?imageView2/0/w/400">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-23.png?imageView2/0/w/400">
<meta property="og:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-24.png?imageView2/0/w/750">
<meta property="article:published_time" content="2021-05-26T00:20:00.000Z">
<meta property="article:modified_time" content="2023-12-03T10:42:00.293Z">
<meta property="article:author" content="胖虎">
<meta property="article:tag" content="redis">
<meta property="article:tag" content="缓存技术">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://myblog.sharemer.com/2021/05/26/20210526-1-1.png?imageView2/0/w/560">


<link rel="canonical" href="http://example.com/2021/05/26/Redis%E7%9F%A5%E8%AF%86%E6%95%B4%E5%90%88%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E9%9B%86%E7%BE%A4/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://example.com/2021/05/26/Redis%E7%9F%A5%E8%AF%86%E6%95%B4%E5%90%88%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E9%9B%86%E7%BE%A4/","path":"2021/05/26/Redis知识整合（四）：集群/","title":"Redis知识整合（四）：集群"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Redis知识整合（四）：集群 | 胖虎de文库</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="胖虎de文库" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">胖虎de文库</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">– – – – – _ _ – _ _ –</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">58</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">18</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">60</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8FDB%E5%B8%B8%E7%94%A8%E7%9A%84%E5%88%86%E5%8C%BA%E6%96%B9%E6%A1%88"><span class="nav-text">一、分布式DB常用的分区方案</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1%EF%BC%9A%E5%8F%96%E6%A8%A1"><span class="nav-text">1.1：取模</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2%EF%BC%9A%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C"><span class="nav-text">1.2：一致性哈希</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-3%EF%BC%9A%E5%93%88%E5%B8%8C%E6%A7%BD"><span class="nav-text">1.3：哈希槽</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81Redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="nav-text">二、Redis集群搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1%EF%BC%9A%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE-%E5%90%AF%E5%8A%A8"><span class="nav-text">2.1：集群配置&amp;启动</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2%EF%BC%9A%E6%8F%A1%E6%89%8B"><span class="nav-text">2.2：握手</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3%EF%BC%9A%E5%88%86%E9%85%8D%E5%93%88%E5%B8%8C%E6%A7%BD"><span class="nav-text">2.3：分配哈希槽</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4%EF%BC%9A%E9%85%8D%E7%BD%AE%E4%B8%BB%E4%BB%8E"><span class="nav-text">2.4：配置主从</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-5%EF%BC%9Aredis-trib-rb"><span class="nav-text">2.5：redis-trib.rb</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1"><span class="nav-text">三、节点通信</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1%EF%BC%9AGossip"><span class="nav-text">3.1：Gossip</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2%EF%BC%9A%E5%AE%9A%E6%97%B6%E6%B6%88%E6%81%AF"><span class="nav-text">3.2：定时消息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3%EF%BC%9A%E6%89%A9%E5%AE%B9"><span class="nav-text">3.3：扩容</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4%EF%BC%9A%E7%BC%A9%E5%AE%B9"><span class="nav-text">3.4：缩容</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-5%EF%BC%9A%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="nav-text">3.5：故障转移</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-6%EF%BC%9A%E8%B7%AF%E7%94%B1"><span class="nav-text">3.6：路由</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-6-1%EF%BC%9A%E9%87%8D%E5%AE%9A%E5%90%91"><span class="nav-text">3.6.1：重定向</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-6-2%EF%BC%9ASmart-Client"><span class="nav-text">3.6.2：Smart Client</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-6-3%EF%BC%9AASK%E9%87%8D%E5%AE%9A%E5%90%91"><span class="nav-text">3.6.3：ASK重定向</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E9%97%AE%E9%A2%98-%E5%BB%BA%E8%AE%AE"><span class="nav-text">四、问题&amp;建议</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1%EF%BC%9A%E9%85%8D%E7%BD%AE%E4%B8%8A%E7%9A%84%E5%BB%BA%E8%AE%AE"><span class="nav-text">4.1：配置上的建议</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2%EF%BC%9A%E5%B8%A6%E5%AE%BD%E5%BC%80%E9%94%80"><span class="nav-text">4.2：带宽开销</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3%EF%BC%9A%E9%9B%86%E7%BE%A4%E5%80%BE%E6%96%9C"><span class="nav-text">4.3：集群倾斜</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4%EF%BC%9A%E6%89%8B%E5%8A%A8%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="nav-text">4.4：手动故障转移</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="胖虎"
      src="https://myblog.sharemer.com/cicada-avatar_00000.png">
  <p class="site-author-name" itemprop="name">胖虎</p>
  <div class="site-description" itemprop="description">Stay young, stay simple.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">58</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">60</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/exceting" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;exceting" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1807301715@qq.com" title="E-Mail → mailto:1807301715@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/22022137/butter-b" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;22022137&#x2F;butter-b" rel="noopener me" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml" rel="noopener me"><i class="fa fa-rss fa-fw"></i></a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/05/26/Redis%E7%9F%A5%E8%AF%86%E6%95%B4%E5%90%88%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E9%9B%86%E7%BE%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://myblog.sharemer.com/cicada-avatar_00000.png">
      <meta itemprop="name" content="胖虎">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="胖虎de文库">
      <meta itemprop="description" content="Stay young, stay simple.">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Redis知识整合（四）：集群 | 胖虎de文库">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Redis知识整合（四）：集群
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-05-26 08:20:00" itemprop="dateCreated datePublished" datetime="2021-05-26T08:20:00+08:00">2021-05-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>24 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><blockquote>
<p>上回主要介绍了redis的主从模式，主从模式最主要的作用是提高redis的可用性，假如主节点挂了，从节点可以在<code>哨兵机制</code>的协助下晋升为主节点继续对外服务，但主从终归是多个redis节点都保存同一份数据，在redis数据快速膨胀时，又该如何应对呢？redis对于这种情况提供了Cluster模式，这是redis的分布式解决方案，使得大批量数据可以拆分成小部分保存进多个redis节点中，本篇笔记将展开说一下<code>Redis Cluster</code>.</p>
</blockquote>
<span id="more"></span>

<h3 id="一、分布式DB常用的分区方案"><a href="#一、分布式DB常用的分区方案" class="headerlink" title="一、分布式DB常用的分区方案"></a>一、分布式DB常用的分区方案</h3><p>分布式数据库在存储全量数据时，首先要解决的是如何把整个数据集按照分区规则映射到多个节点上：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-1.png?imageView2/0/w/560" alt="图1"></p>
<p>这里介绍几个常用分分区方案：</p>
<h4 id="1-1：取模"><a href="#1-1：取模" class="headerlink" title="1.1：取模"></a>1.1：取模</h4><p>这是最常用的方式，假如现在有N个存储节点，则计算方式为：p &#x3D; hash(key) % N，也就是取唯一标识（在本例中就是redis key）进行哈希计算后跟当前节点数取模，最终就可以得出这条数据会被分配到哪台机器上，这是这种方式的优缺点：</p>
<ul>
<li>优点：简单易用</li>
<li>缺点：扩缩容时可能导致全部节点失效（<code>rehash</code>），建议扩缩容时按照<code>原节点数 × 2</code>来进行，这样只要原来的哈希值不变，余数也就不会变</li>
</ul>
<h4 id="1-2：一致性哈希"><a href="#1-2：一致性哈希" class="headerlink" title="1.2：一致性哈希"></a>1.2：一致性哈希</h4><p>这种方式的实现思路是为每个节点分配一个token值，取值范围在0~2^32间，当给节点分配完token，这些节点就会形成一个闭环：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-2.png?imageView2/0/w/600" alt="图2"></p>
<p>当有新的数据到来时，跟前面一样先计算出唯一标识（key）的哈希值，然后拿着这个哈希值顺时针找到第一个大于等于该值的token（找不到比自身大的token就放进顺时针第一个节点中，所以才说这是个闭合的环嘛），将其存入该token对应的节点中：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-3.png?imageView2/0/w/650" alt="图3"></p>
<p>这样一来，增减节点时只会影响哈希环中相邻的节点，对其他节点无影响：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-5.png?imageView2/0/w/1100" alt="图4"></p>
<p>至于加减节点导致的一小部分数据不可用，需要手动处理，如果利用一致性哈希存缓存数据，那么也可以忽略这部分数据，等回源时再次写入正确的节点即可。</p>
<p>如果节点过少，则节点变化将大范围影响哈希环中的数据映射，而且数据会严重倾斜，所以一致性哈希不适合节点数较少时使用。</p>
<p>在使用一致性哈希时，节点扩缩容容易导致负载不均衡（如图4），尤其是删除一个节点时，被删节点的负载将全部打到下一个节点，如果下一个节点不堪重负挂掉，此时更大的压力将会顺延至下下一个节点，以此类推，最终可能导致服务全员故障，为了解决一致性哈希的这些问题，诞生了<code>虚拟节点</code>的概念，这是对一致性哈希算法的优化，算法的本质没有变化，但与之前不同的是现在数据不与实际的节点交互而是跟抽象出来的虚拟节点交互：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-7.png?imageView2/0/w/600" alt="图5"></p>
<p>图中简化了，实际上虚拟节点是逻辑层面的节点，数量会非常多。</p>
<p>加这一层虚拟节点做一致性哈希的代理层，然后再将虚拟节点映射到具体的机器上，只要这个映射逻辑足够散列，那么之前的问题将不复存在，比如现在我们去掉一个节点：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-9.png?imageView2/0/w/600" alt="图6"></p>
<p>可以看到，受被删节点影响的数据最终会被节点2和节点3的虚拟节点接收，这就是虚拟节点比原生一致性哈希优秀的地方，通过一层抽象，解决了一致性哈希的痛点。</p>
<h4 id="1-3：哈希槽"><a href="#1-3：哈希槽" class="headerlink" title="1.3：哈希槽"></a>1.3：哈希槽</h4><p>它结合了上述两种哈希算法的特点实现，首先它会抽象出来一大堆的哈希槽，这些哈希槽都有自己编号，每个物理节点负责存储一定范围内的哈希槽，存储数据时跟前两种哈希算法一样，先计算出唯一标识（key）的哈希值，然后看该值在哪个槽区间里，若命中区间，则存进负责该槽区间的节点：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-10.png?imageView2/0/w/600" alt="图7"></p>
<p>增减节点时需要重新分配每个节点负责的槽范围，将一些错位数据做迁移，这样可以保证每个节点仍然是均匀的负责一个哈希槽区间，也就自然不存在数据倾斜等问题，Redis Cluster正是采用哈希槽的方式实现数据分区的，它一共有16383个槽位，流程跟<code>图7</code>中描绘的一样，分区算法为：<code>CRC16(key) % 16383</code></p>
<h3 id="二、Redis集群搭建"><a href="#二、Redis集群搭建" class="headerlink" title="二、Redis集群搭建"></a>二、Redis集群搭建</h3><h4 id="2-1：集群配置-启动"><a href="#2-1：集群配置-启动" class="headerlink" title="2.1：集群配置&amp;启动"></a>2.1：集群配置&amp;启动</h4><p>redis集群一般需要至少6个节点（3主3从）才能保证组成完整的高可用集群，单节点的redis-6379.conf主要配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">port 6379 #端口号</span><br><span class="line">cluster-enabled yes #开启集群模式</span><br><span class="line">cluster-node-timeout 15000 #节点超时时间（单位：ms）</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">↓集群配置文件，若没有则自动创建，当集群内节点信息发生变化（如添加/下线节点、故障转移等），节点</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">会自动保存集群状态到该配置文件中（redis自动维护该文件，不需要手动修改）</span></span><br><span class="line">cluster-config-file &quot;node-6379.conf&quot;</span><br></pre></td></tr></table></figure>

<p>配置完成后将所有节点都启动起来，假设有这样6个节点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">redis-server conf/redis-6379.conf</span><br><span class="line">redis-server conf/redis-6380.conf</span><br><span class="line">redis-server conf/redis-6381.conf</span><br><span class="line">redis-server conf/redis-6382.conf</span><br><span class="line">redis-server conf/redis-6383.conf</span><br><span class="line">redis-server conf/redis-6384.conf</span><br></pre></td></tr></table></figure>

<p>启动完成后，来随便看一个节点的集群配置文件，比如node-6379.conf：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">5adabec665d2b4005adabec665d2b40adabec665 127.0.0.1:6379 myself,master - 0 0 0 connected vars currentEpoch 0 lastVoteEpoch 0</span><br></pre></td></tr></table></figure>

<p>这里面记录的是集群的初始状态，其中第一个40位的十六进制字符串表示的是节点ID，它是节点在集群中的唯一标识，很多集群操作都需要借助这个ID来完成（ID在初始化集群时生成，节点重启会重用）</p>
<h4 id="2-2：握手"><a href="#2-2：握手" class="headerlink" title="2.2：握手"></a>2.2：握手</h4><p>到上面的步骤为止，节点只是打开了集群模式，完成了启动，它们彼此并不知道彼此的节点信息，接下来这一步操作就可以让它们感知到身处同一个集群里的彼此，这个操作由客户端发起：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster meet $&#123;ip&#125; $&#123;port&#125;</span><br></pre></td></tr></table></figure>

<p>发送meet就可以让节点间进行握手通信，就像下面这样：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-11.png?imageView2/0/w/700" alt="图8"></p>
<p>当某个节点对着其他节点全部发一次meet消息后，集群中每个节点就会慢慢感知到其他的节点，最终在每一个节点内执行下面这个命令，都可以获取到所有的节点信息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; cluster nodes</span><br><span class="line">5adabec665d2b4005adabec665d2b40adabec665 127.0.0.1:6379 myself,master - 0 0 0 connected</span><br><span class="line">8ebabevc789d2b6125becbec123d2f45adabecec 127.0.0.1:6380 master - 0 146345454 1 connected</span><br><span class="line">fdadadacddd2b4666adabec125d2aaaadabecdec 127.0.0.1:6381 master - 0 146345454 2 connected</span><br><span class="line">dddddddcddd5bbbbbadabec567d2bb0adabecfed 127.0.0.1:6382 master - 0 146345454 3 connected</span><br><span class="line">fadabec567d6bddddadabec690d2b40adabecede 127.0.0.1:6383 master - 0 146345454 4 connected</span><br><span class="line">dadacecef8d1b4a85adabece76d2b40adabecded 127.0.0.1:6384 master - 0 146345454 5 connected</span><br></pre></td></tr></table></figure>

<p>至于meet的过程，我们放到后面详细说。</p>
<p>节点建立握手后，集群还无法工作，整体处于下线状态，所有数据的读写都会被禁止，这是因为还没给主节点分配槽位，没有槽位连插入的数据放到哪个节点都不知道。</p>
<h4 id="2-3：分配哈希槽"><a href="#2-3：分配哈希槽" class="headerlink" title="2.3：分配哈希槽"></a>2.3：分配哈希槽</h4><p>redis是通过哈希槽进行数据分区的，这在之前已经提过了，分配槽位用到的指令是：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster addslots &#123;x...y&#125; #xy就是当前节点负责的槽范围</span><br></pre></td></tr></table></figure>

<p>我们设6379&#x2F;6380&#x2F;6381三个节点为主节点，将16384个槽均匀分配给这三个节点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p 6379 cluster addslots &#123;0...5461&#125;</span><br><span class="line">redis-cli -h 127.0.0.1 -p 6380 cluster addslots &#123;5462...10922&#125;</span><br><span class="line">redis-cli -h 127.0.0.1 -p 6381 cluster addslots &#123;19023...16383&#125;</span><br></pre></td></tr></table></figure>

<p>在每个分配好槽位的主节点执行<code>cluster info</code>可以查看具体的集群状态信息，使用<code>cluster nodes</code>则可以查看整个集群的情况：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; cluster nodes</span><br><span class="line">5adabec665d2b4005adabec665d2b40adabec665 127.0.0.1:6379 myself,master - 0 0 0 connected 0-5461</span><br><span class="line">8ebabevc789d2b6125becbec123d2f45adabecec 127.0.0.1:6380 master - 0 146345454 1 connected 5462-10922</span><br><span class="line">fdadadacddd2b4666adabec125d2aaaadabecdec 127.0.0.1:6381 master - 0 146345454 2 connected 10923-16383</span><br><span class="line">dddddddcddd5bbbbbadabec567d2bb0adabecfed 127.0.0.1:6382 master - 0 146345454 3 connected</span><br><span class="line">fadabec567d6bddddadabec690d2b40adabecede 127.0.0.1:6383 master - 0 146345454 4 connected</span><br><span class="line">dadacecef8d1b4a85adabece76d2b40adabecded 127.0.0.1:6384 master - 0 146345454 5 connected</span><br></pre></td></tr></table></figure>

<p>相比之前，三个主节点已经输出了自己负责的槽位信息。</p>
<h4 id="2-4：配置主从"><a href="#2-4：配置主从" class="headerlink" title="2.4：配置主从"></a>2.4：配置主从</h4><p>上述集群中还有3个节点没有利用到，这3个节点就是我们要设置的从节点，在集群模式下建立主从关系有些不太一样，用的是这个指令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster replicate $&#123;master-node-id&#125;</span><br></pre></td></tr></table></figure>

<p>在集群中，从节点负责复制主节点的槽信息和数据。虽然指令不同，但复制的流程则和原来讲的普通主从模式一致，最终我们这个集群的完整拓补图将会是下面这样：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-12.png?imageView2/0/w/600" alt="图9"></p>
<p>此时如果再执行<code>cluster nodes</code>命令，主从信息也会被打印出来（这里不再演示）。</p>
<h4 id="2-5：redis-trib-rb"><a href="#2-5：redis-trib-rb" class="headerlink" title="2.5：redis-trib.rb"></a>2.5：redis-trib.rb</h4><p>如果你觉得上面的流程太过复杂，没关系，redis提供了官方的快速搭建集群的工具：redis-trib.rb，它采用ruby实现，可以帮我们简化集群创建、检查、迁移槽、均衡等常见运维操作。</p>
<p>使用前需要先装ruby：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">wget https://cache.ruby-lang.org/pub/ruby/$&#123;big_ver&#125;/ruby-$&#123;ver&#125;.tar.gz #下载压缩包，big_ver为大版本号，如2.3，ver为具体版本号，如2.3.1</span><br><span class="line">tar xvf ruby-yy.tar.gz #解压</span><br><span class="line">./configure -prefix=/usr/local/ruby</span><br><span class="line">make #编译</span><br><span class="line">make install</span><br><span class="line">cd /usr/local/ruby</span><br><span class="line">sudo cp bin/ruby /usr/local/bin</span><br><span class="line">sudo cp bin/gem /usr/local/bin</span><br></pre></td></tr></table></figure>

<p>安装rubygem redis依赖：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://rubygems.org/downloads/redis-$&#123;ver&#125;.gem #下载redis.gem，ver是具体的版本号，如3.3.0</span><br><span class="line">gem install -l redis-$&#123;ver&#125;.gem</span><br><span class="line">gem list --check redis gem</span><br></pre></td></tr></table></figure>

<p>安装redis-trib.rb：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /$&#123;redis_home&#125;/src/redis-trib.rb /usr/local/bin</span><br></pre></td></tr></table></figure>

<p>安装完ruby环境后，执行redis-trib.rb命令确认环境是否正确即可，若准确则打印相关信息。</p>
<p>然后开始创建集群：</p>
<p>①首先准备好6个开启集群模式节点，过程跟之前一样，不再赘述。</p>
<p>②执行redis-trib.rb创建集群：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-trib.rb create --replicas 1 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384</span><br></pre></td></tr></table></figure>

<p><code>--replicas</code>可以指定每个主节点配置几个从节点，这里设置的是1，如果是多台机器部署，redis-trib.rb会尽可能保证主从不在同一个机器里（不然会弱化高可用）</p>
<p>上面的指令执行后，会将当前的主从分配信息打印出来，然后征求你的同意，你只要输入了<code>yes</code>，redis-trib.rb就会紧接着进行节点握手和槽分配；相比原生搭建集群，redis-trib.rb的确可以帮我们省去很多麻烦。</p>
<h3 id="三、节点通信"><a href="#三、节点通信" class="headerlink" title="三、节点通信"></a>三、节点通信</h3><h4 id="3-1：Gossip"><a href="#3-1：Gossip" class="headerlink" title="3.1：Gossip"></a>3.1：Gossip</h4><p>如<code>图8</code>所示，为什么某个节点对着其他节点全部发一次meet消息后，每个节点就会慢慢感知到其他的节点呢？这是因为redis利用<code>Gossip</code>协议（一种分布式一致性协议，为最终一致）做信息同步，Gossip的工作原理就是节点间彼此不断的通信进行信息交换，这样持续一段时间后，所有的节点就都知道了集群的完整信息（这种方式很像流言的传播，所以Gossip协议也叫流言协议），过程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-13-fix2.png?imageView2/0/w/1400" alt="图10"></p>
<p>注意图中的流程是按照6379的meet消息同时发到各节点，各节点又同时发pong给6379的，但实际操作中这肯定不是同时发生的，但这并不影响节点的传播。</p>
<p>上面所涉及到的<code>meet</code>、<code>ping</code>、<code>pong</code>消息均为Redis Gossip消息，除了这些还有<code>fail</code>消息，当任意节点发现某一个节点挂掉后，会向集群内广播一个fail消息，其他节点接收到这条fail消息后会把对应的坏节点更新为下线状态（后面会详细介绍<code>故障转移</code>）。</p>
<h4 id="3-2：定时消息"><a href="#3-2：定时消息" class="headerlink" title="3.2：定时消息"></a>3.2：定时消息</h4><p>上面的流程图告诉我们集群内的每个节点都会定时对其他节点通信进行信息交换，频率是10次&#x2F;秒，高频是为了让信息扩散的更快，可是这样就会导致另一个问题：每次请求都携带很多信息（比如自身和其他节点的状态信息等），这样势必会造成网络带宽的浪费；为了解决这一问题，节点间每次只选取部分节点进行通信，选取逻辑主要源自两部分，这里以6379这个节点（定时发ping消息）为例：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-14.png?imageView2/0/w/850" alt="图11"></p>
<p>根据这两个选取规则可以估算出每个节点每秒需要发送的消息数为：<code>1 + 10 * num(node.pong_last_time &gt; cluster_node_timeout/2)</code>，其中<code>cluster_node_timeout</code>可配，默认15s，当我们的带宽资源紧张时可以适当调大该值来降低贷款占用率，当然扩大该值意味着故障转移、槽信息更新、新节点发现等信息的同步速度降低，所以调整该值大小需要仔细斟酌，有得必有失。</p>
<p>除了削减每次发送的消息数量，还缩小了每次发送的数据包，每条Gossip消息都由消息头和消息体组成，其中消息头中的myslots字段（自己负责的槽信息，约占2kb），而主要的削减对象是消息体，消息体中主要携带其他节点的信息，用于信息交换，但每次都全量携带所有节点的信息显然太浪费，所以Redis进行了削减，每次只携带<code>cluster.nodes.size/10</code>个其他节点的信息。</p>
<h4 id="3-3：扩容"><a href="#3-3：扩容" class="headerlink" title="3.3：扩容"></a>3.3：扩容</h4><p>前面我们就讲过集群中的每条数据都会通过哈希计算被映射进一个槽位，而每个槽位又按照编号均匀分布在集群的每个节点中，所以扩缩容说白了就是槽和数据在各个节点间移动。现在我们假设给集群加入了两个节点，它们融入进cluster的流程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-15.png?imageView2/0/w/1100" alt="图10"></p>
<p>截至目前，新节点依旧没有对外服务，因为还没分配槽，只要两个节点有一个不是从节点（假设6385非从），那么slots一定会重新分配，就像这样（其他主节点匀给新节点一部分slots）：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-16.png?imageView2/0/w/380" alt="图11"></p>
<p>迁移过程较复杂，我们以一个槽位的迁移为切入点进行详细介绍，假设现在要将6381的某个槽对应的数据迁移到6385，过程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-17.png?imageView2/0/w/650" alt="图12"></p>
<p>这个过程很复杂，如果全部通过手动来做那肯定不合适，所以redis-trib.rb为我们提供了槽重新分片的功能：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-trib.rb reshard $&#123;host:port&#125; --from $&#123;source-node-id&#125; --to $&#123;target-node-id&#125; --slots $&#123;need-migrate-slots-total&#125; --yes --timeout $&#123;pre-migrate-timeout&#125; --pipline $&#123;per-migrate-key-total&#125;</span><br></pre></td></tr></table></figure>

<p>入参释义：</p>
<ol>
<li>host:port：必传，是集群中任意节点的地址，用来获取整个集群的信息</li>
<li>source-node-id：源节点id，可用逗号传多个</li>
<li>target-node-id：目标节点id，只允许填写一个，例如图11中就可以认为source-node-id是6379&#x2F;6380&#x2F;6381三个节点，而目标节点就是6385</li>
<li>need-migrate-slots-total：需要迁移的槽的总数量，新增主节点可以根据16384&#x2F;nodes.size估算出来</li>
<li>pre-migrate-timeout：单次migrate超时时间，缺省值：60000ms</li>
<li>per-migrate-key-total：单次migrate迁移的键数量，缺省值：10</li>
</ol>
<blockquote>
<p>ps：因为reshard命令每次只允许指定一个<code>目标节点</code>，所以当扩容多个节点时需要一个个的进行迁移（此时被加进来的节点为<code>目标节点</code>），而缩容时如果需要缩多个节点，可以将这些下线节点同时指定为源节点，但迁移至其集群内其他节点时也需要一个个执行（此时其他节点为<code>目标节点</code>）。</p>
</blockquote>
<h4 id="3-4：缩容"><a href="#3-4：缩容" class="headerlink" title="3.4：缩容"></a>3.4：缩容</h4><p>理解了扩容，缩容就好理解了，如果要从集群下掉一个节点，流程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-18.png?imageView2/0/w/500" alt="图13"></p>
<p><strong>1.迁移槽</strong></p>
<p>假如我们要将上面例子中的某个主节点下掉，这里槽迁移过程和扩容时是一样的，唯一的不同点是现在的目标节点有三个，而源节点只有一个，所以需要将源节点里的槽位列出来，算出来其负责的槽位数，然后用<code>槽位数/3</code>计算出其余三个节点均摊多少槽位，然后分三次reshard即可。</p>
<p><strong>2.忘记节点</strong></p>
<p>通过以下命令来完成：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">向集群内每个节点发送下面的命令，发送后对应节点就会把下线节点加入到禁用列表里，</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">处于禁用列表中的node不再参与Gossip通信，但该列表只有60s有效期，所以得在过</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">期前让集群内所有节点都收到cluster forget指令</span></span><br><span class="line">cluster forget $&#123;target-node-id&#125;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">如果觉得上面的流程麻烦，还可以使用redis-trib对着任意集群节点发送以下指令</span></span><br><span class="line">redis-trib.rb del-node $&#123;host:port&#125; $&#123;target-node-id&#125;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">↑上面这个指令内部逻辑就是循环集群内其他节点挨个发cluster forget指令，除此</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">之外，它还会将下线节点的从节点（如果有的话）指向别的主节点（原则上是指定给从</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">节点最少的那个主节点）</span></span><br></pre></td></tr></table></figure>

<h4 id="3-5：故障转移"><a href="#3-5：故障转移" class="headerlink" title="3.5：故障转移"></a>3.5：故障转移</h4><p>通过前面几个小节，我们知道了redis集群如何做心跳检查和扩缩容，这一小节，我们就来聊聊故障的转移。</p>
<p>一个正常集群内的各个节点会定期发送ping&#x2F;pong消息，用来同步集群信息和做心跳检查（参考<code>图11</code>），那么自然也会通过这种方式发现故障节点，通过图11我们知道，一个节点与另一个节点间的ping消息正常情况下不会超出<code>cluster_node_timeout</code>，若超过，说明ping消息失败且重连失败，导致cluster_node_timeout一直得不到刷新，这时便可以判定对方为<code>主观下线（pfail）</code>，现在还不能给这个节点判死刑，因为单台机器认定的故障不具备权威性，这条主观下线信息最终会被传播出去，当超过半数的主节点均认为该节点下线时，此时这个节点才是真正意义上的下线，即<code>客观下线</code>，详细流程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-25.png?imageView2/0/w/860" alt="图14"></p>
<p>故障节点变为<code>客观下线</code>后，如果被下线的节点持有槽，那么接下来就需要<code>故障恢复</code>，当它的从节点也收到客观下线的消息时，就开始选举一个能替换它对外服务的节点作为新的主节点，选举和恢复流程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-27.png?imageView2/0/w/980" alt="图15"></p>
<p>故障转移时间跟所配的cluster-node-timeout息息相关（默认15s），配置时可以根据业务容忍度做出适当的调整。</p>
<h4 id="3-6：路由"><a href="#3-6：路由" class="headerlink" title="3.6：路由"></a>3.6：路由</h4><h5 id="3-6-1：重定向"><a href="#3-6-1：重定向" class="headerlink" title="3.6.1：重定向"></a>3.6.1：重定向</h5><p>槽分配都是在服务端完成的，且服务端每个节点都保存有一份当前的槽信息，那客户端要如何准确的访问整个集群呢？redis官方的做法是让客户端无脑发起直连，被连到的服务端做路由分析与转发，流程如下：</p>
<p>前两种方案都是建立在服务端节点无作为的情况下进行的，这样做有一个坏处，Gossip协议是最终一致的，那么槽信息的同步必定会存在延迟，这样在做槽迁移时会存在大量路由错误的key，而且第二种方案还加大了系统的复杂度，得不偿失。</p>
<p>第三种方案是服务端自身做路由转发，这也就意味着服务端节点本身具备判断槽分配的能力，即便是正在槽迁移，路由至错误节点，错误节点也能很好的更正路由（多次路由转发必定会找到正确的那个节点），而且这个方案并没有额外增加模块，没有增加维护成本，所以redis官方采用了这种方案，流程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-19.png?imageView2/0/w/560" alt="图16"></p>
<p>客户端指令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -p 6379</span><br><span class="line">127.0.0.1:6379&gt; set $&#123;key&#125; $&#123;value&#125;</span><br><span class="line">(error) MOVED $&#123;slot-num&#125; 127.0.0.1:6381 #表示当前key所属槽分布在6381上</span><br><span class="line"></span><br><span class="line">127.0.0.1:6381&gt; set $&#123;key&#125; $&#123;value&#125;</span><br><span class="line">OK #重新到6381上则顺利执行</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">你或许觉得上面的操作过于麻烦，没关系，还可以给redis-cli加-c自动路由（内部逻辑跟上面是一样的，只是redis-cli帮我们屏蔽掉了）</span></span><br><span class="line">redis-cli -p 6379 -c</span><br><span class="line">127.0.0.1:6379&gt; set $&#123;key&#125; $&#123;value&#125;</span><br><span class="line"><span class="meta prompt_">-&gt; </span><span class="language-bash">Redirected to slot [<span class="variable">$&#123;slot-num&#125;</span>] located at 127.0.0.1:6381 <span class="comment">#即便在6379上执行，也可以自动路由</span></span></span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<blockquote>
<p>集群环境下，不能很好的支持<code>mget</code>等批量命令，因为多个key无法保证都落到同一个节点上，可以通过<code>&#123;&#125;</code>做路由控制，因为cluster做哈希计算时如果发现key里包含一对<code>&#123;&#125;</code>，则只让<code>&#123;&#125;</code>内的部分参与哈希计算，可以通过这个特点来让一些需要批量操作的key落入同一个节点内。</p>
</blockquote>
<p>集群中每个节点都保存一份完整的slot-node映射关系，其保存在<code>clusterState</code>结构中：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">clusterState</span> &#123;</span></span><br><span class="line">    clusterNode *myself; <span class="comment">//自身节点</span></span><br><span class="line">    clusterNode *slots[CLUSTER_SLOTS]; <span class="comment">//16384个槽-节点映射数组，下标为槽</span></span><br><span class="line">    ...略</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面客户端请求重定向的逻辑伪代码如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def <span class="title function_">execute_or_redirect</span><span class="params">(key)</span>:</span><br><span class="line">	<span class="type">int</span> slot = key_hash_slot(key);</span><br><span class="line">	ClusterNode node = slots[slot];</span><br><span class="line">	<span class="keyword">if</span>(node == clusterState.myself):</span><br><span class="line">		<span class="keyword">return</span> executeCommand(key);</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="string">&#x27;(error) MOVED [slot-num] [ip]:[port]&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>通过上面的了解，我们知道了客户端与集群交互的基本流程，但这个流程存在一个问题，倘若大部分时候都请求不到准确的节点，那岂不是意味着客户端大部分访问都需要通信两次才能完成？这对IO来说是笔不菲的开销，有没有更聪明的办法来做路由呢？</p>
<h5 id="3-6-2：Smart-Client"><a href="#3-6-2：Smart-Client" class="headerlink" title="3.6.2：Smart Client"></a>3.6.2：Smart Client</h5><p>事实上现在大部分语言的客户端都解决了这个问题，比如<code>Jedis</code>，解决办法就是在本地直接缓存下来slot-node映射信息（初始化时访问任意节点发送<code>cluster slots</code>指令即可获得），等key来了可以直接在客户端做好路由发给正确的节点，当偶尔发生MOVE响应时就更新本地的映射信息。</p>
<p>拿<code>JedisCluster</code>来说，它的处理流程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-20.png?imageView2/0/w/700" alt="图17"></p>
<p>上面在出问题的情况下（比如连接出错、重定向）会重试一定的次数，当超出重试个数就会抛出以下异常：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JedisClusterMaxRedirectionsException(<span class="string">&quot;Too many Cluster redirections?&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>所以不管是太多次连接出错，还是大量重定向发生，都会抛出这个异常。</p>
<h5 id="3-6-3：ASK重定向"><a href="#3-6-3：ASK重定向" class="headerlink" title="3.6.3：ASK重定向"></a>3.6.3：ASK重定向</h5><p>这绝对是我最感兴趣的部分，参考<code>图12</code>，如果客户端在发送命令时redis集群正在进行槽迁移，那么势必会出现下面这种情况：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-22.png?imageView2/0/w/400" alt="图18"></p>
<p>出现了上面的问题，如果要保证客户端的可用性，此时源节点肯定会通知客户端重定向至目标节点，那么redis具体是怎么做的呢？答案就是<code>ASK重定向</code>，与<code>MOVED重定向</code>有一些不同，它只会发生在槽迁移阶段，它的具体流程如下：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-23.png?imageView2/0/w/400" alt="图19"></p>
<p>通过这个流程可以保证在槽迁移过程中客户端也能很好的得到响应，再来看看服务端具体的处理流程：</p>
<p><img src="http://myblog.sharemer.com/2021/05/26/20210526-1-24.png?imageView2/0/w/750" alt="图20"></p>
<h3 id="四、问题-建议"><a href="#四、问题-建议" class="headerlink" title="四、问题&amp;建议"></a>四、问题&amp;建议</h3><h4 id="4-1：配置上的建议"><a href="#4-1：配置上的建议" class="headerlink" title="4.1：配置上的建议"></a>4.1：配置上的建议</h4><p><code>3.5</code>中的故障转移过程中整个集群是不可用状态，可以通过将<code>cluster-require-full-coverage</code>设为<code>no</code>来保证出现故障时其他未故障节点可用。</p>
<h4 id="4-2：带宽开销"><a href="#4-2：带宽开销" class="headerlink" title="4.2：带宽开销"></a>4.2：带宽开销</h4><p>Redis对带宽的消耗主要体现在两方面，一是Gossip本身会消耗带宽，二是指令处理，官方建议redis集群最大规模在1000以内，也是出于对消息通信成本的考虑，可以通过增加物理机器来增加整体带宽；</p>
<p>提高cluster-node-timeout可以降低Gossip通信速率，但同样会影响故障转移的速度，请酌情选择合适的值。</p>
<p>如果条件允许，集群尽量部署在更多的机器上，如果大量的节点集中部署在少量物理机器上，这时机器的带宽消耗将非常严重。</p>
<h4 id="4-3：集群倾斜"><a href="#4-3：集群倾斜" class="headerlink" title="4.3：集群倾斜"></a>4.3：集群倾斜</h4><p>导致集群倾斜的原因和解决之道：</p>
<ul>
<li>节点和槽分布严重不均：可以通过<code>redis-trib.rb rebalance</code>均衡槽的分配</li>
<li>不同槽对应的键数量差异过大：我们知道键通过CRC16哈希函数映射到槽上，正常情况下槽内键数会相对均匀，但当大量使用hash_tag时（例如user:user1:ids，user1就是hash_tag），会有不同的键映射到同一个槽的情况，通过命令<code>cluster countkeysinslot $&#123;slot&#125;</code>可以获得槽对应的键数，识别出哪些槽映射了过多的键，再通过命令<code>cluster getkeysinslot $&#123;slot&#125; $&#123;count&#125;</code>迭代出槽下所有的键，从而发现过度使用hash_tag的键。</li>
<li>集合对象包含大量元素：大集合对象可在客户端通过<code>--bigkeys</code>指令输出，找出大集合后可根据业务场景进行拆分（大集合的键迁移时还容易超时导致失败）</li>
<li>内存相关配置不一致：集群内各节点的内存配置要保持一致（比如xxxx-max-ziplist-value等）。</li>
</ul>
<h4 id="4-4：手动故障转移"><a href="#4-4：手动故障转移" class="headerlink" title="4.4：手动故障转移"></a>4.4：手动故障转移</h4><p>在从节点执行<code>cluster failover</code>命令将会发起故障转移流程。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="https://myblog.sharemer.com/wx_qrcode.png" alt="胖虎 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="https://myblog.sharemer.com/alipay_qrcode.png" alt="胖虎 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          <div class="post-tags">
              <a href="/tags/redis/" rel="tag"><i class="fa fa-tag"></i> redis</a>
              <a href="/tags/%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF/" rel="tag"><i class="fa fa-tag"></i> 缓存技术</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/05/24/Redis%E7%9F%A5%E8%AF%86%E6%95%B4%E5%90%88%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E9%AB%98%E5%8F%AF%E7%94%A8-%E4%B8%BB%E4%BB%8E/" rel="prev" title="Redis知识整合（三）：高可用-主从">
                  <i class="fa fa-angle-left"></i> Redis知识整合（三）：高可用-主从
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/07/03/MySQL%E7%9F%A5%E8%AF%86%E6%95%B4%E5%90%88%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AInnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/" rel="next" title="MySQL知识整合（一）：InnoDB存储引擎">
                  MySQL知识整合（一）：InnoDB存储引擎 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">胖虎</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">185k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">11:14</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>
    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/exceting" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"exceting","repo":"exceting.github.io","client_id":"bf1128ab98604ef89632","client_secret":"ccd78d69fca17fc20f0d794356d1100417b78d0a","admin_user":"exceting","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"517af67e45ba103530ecf4796b6a0a87"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
